# Guide de Test Complet - DGI-NetWatch

## üìã Pr√©requis et Contexte d'Ex√©cution

### O√π Ex√©cuter les Commandes?

| Contexte | O√π | Acc√®s Requis | R√¥le |
|----------|-----|-------------|------|
| **Commandes kubectl** | **Votre machine locale OU runner GitHub Actions** | Kubeconfig configur√© | Developer/Admin cluster |
| **Port-forward** | **Votre machine locale uniquement** | Kubectl + Pod access | Developer |
| **Exec dans pods** | **Votre machine locale OU runner GitHub** | Kubectl + Pod exec | Developer |
| **Terraform** | **Votre machine locale OU runner GitHub** | GCP credentials | GCP Project Editor |

### Configuration Locale Requise

```bash
# V√©rifier kubectl est install√© et configur√©
kubectl version --client

# V√©rifier la connexion au cluster
kubectl cluster-info

# V√©rifier votre contexte actuel
kubectl config current-context

# V√©rifier que vous avez acc√®s au namespace production
kubectl auth can-i get namespaces --namespace=production
kubectl auth can-i get pods --namespace=production
```

### Variables d'Environnement √† Conna√Ætre

```bash
# GCP/GKE
export GCP_PROJECT_ID="dgi-cosmic-20251210-1542"
export GKE_CLUSTER_NAME="dgi-cluster"
export GKE_REGION="us-central1"

# Kubernetes
export K8S_NAMESPACE="production"
export BACKEND_SERVICE="dgi-netwatch-backend"
export FRONTEND_SERVICE="dgi-netwatch-frontend-service"
```

---

## 1. V√©rifier les Ressources Kubernetes

**O√π ex√©cuter:** Machine locale (terminal avec kubectl configur√©) ou GitHub Actions runner
**Acc√®s requis:** Lecture sur namespace production

```bash
# V√©rifier que le namespace existe
kubectl get namespace production

# V√©rifier les d√©ploiements
kubectl get deployments -n production
kubectl describe deployment dgi-netwatch-backend -n production
kubectl describe deployment dgi-netwatch-frontend -n production

# V√©rifier les pods
kubectl get pods -n production
kubectl describe pods -n production
```

## 2. V√©rifier l'√âtat des Pods

**O√π ex√©cuter:** Machine locale (terminal avec kubectl) ou GitHub Actions
**Acc√®s requis:** Lecture logs des pods
**R√¥le:** Developer minimum

```bash
# Voir les logs du backend
kubectl logs -n production -l app=dgi-netwatch-backend --tail=50

# Voir les logs du frontend (nginx)
kubectl logs -n production -l app=dgi-netwatch-frontend --tail=50

# Streaming des logs en temps r√©el
kubectl logs -f -n production -l app=dgi-netwatch-backend

# Si un pod a plusieurs conteneurs:
kubectl logs <POD_NAME> -n production -c backend
```

**Qu'attendre:** Pas d'erreurs critiques dans les logs

## 3. V√©rifier les Services et R√©seau

**O√π ex√©cuter:** Machine locale avec kubectl ou GitHub Actions
**Acc√®s requis:** Lecture sur services/endpoints
**R√¥le:** Developer minimum

```bash
# V√©rifier les services
kubectl get svc -n production

# Format personnalis√© pour voir les d√©tails
kubectl get svc -n production -o wide

# Voir les endpoints (pods r√©ellement accessibles)
kubectl get endpoints -n production

# D√©tails d'un service
kubectl describe svc dgi-netwatch-backend -n production
kubectl describe svc dgi-netwatch-frontend-service -n production
```

**Qu'attendre:** 
- Backend service en ClusterIP sur port 3001
- Frontend service en ClusterIP sur port 80
- Endpoints montrent les IPs des pods

## 4. Acc√©der au Frontend Localement

**O√π ex√©cuter:** Machine locale UNIQUEMENT (port-forward ne fonctionne que localement)
**Acc√®s requis:** Exec sur pods + port-forward
**R√¥le:** Developer minimum

```bash
# Terminal 1: Configurer le port-forward
kubectl port-forward svc/dgi-netwatch-frontend-service 8080:80 -n production

# Output attendu:
# Forwarding from 127.0.0.1:8080 -> 80
# Forwarding from [::1]:8080 -> 80

# Terminal 2: Ouvrir le navigateur
# URL: http://localhost:8080
```

**Qu'attendre:**
- Le port 8080 local redirige vers le service frontend
- Page HTML charge (frontend Vite/React)
- Pas d'erreurs CORS ou de connectivit√©

**Troubleshooting:**
- Si le port 8080 est d√©j√† utilis√©: `kubectl port-forward svc/dgi-netwatch-frontend-service 8081:80 -n production`

## 5. Tester la Connectivit√© Backend

**O√π ex√©cuter:** Machine locale (terminal s√©par√© pour port-forward)
**Acc√®s requis:** Exec et port-forward
**R√¥le:** Developer

```bash
# Terminal 1: Port-forward le backend
kubectl port-forward svc/dgi-netwatch-backend 3001:3001 -n production

# Terminal 2: Tester l'endpoint de sant√©
curl http://localhost:3001/api/sante

# Tester les autres endpoints (adapter selon votre API)
curl http://localhost:3001/api/status
curl http://localhost:3001/health

# Avec verbose pour debug
curl -v http://localhost:3001/api/sante
```

**Qu'attendre:**
- R√©ponse 200 OK sur /api/sante
- JSON valide en r√©ponse
- Headers Content-Type: application/json

## 6. Tester depuis √† l'Int√©rieur d'un Pod (Pod-to-Pod)

**O√π ex√©cuter:** Machine locale avec kubectl (exec acc√®de au pod)
**Acc√®s requis:** Exec sur pods
**R√¥le:** Developer

```bash
# M√©thode 1: Lancer un pod temporaire de debug
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -n production -- sh

# √Ä l'int√©rieur du pod:
# Tester la connectivit√© vers le backend depuis n'importe o√π dans le cluster
curl http://dgi-netwatch-backend:3001/api/sante

# Tester la r√©solution DNS
nslookup dgi-netwatch-backend
nslookup dgi-netwatch-backend.production.svc.cluster.local

# Quitter avec: exit

# M√©thode 2: Exec dans un pod existant
POD_BACKEND=$(kubectl get pod -n production -l app=dgi-netwatch-backend -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $POD_BACKEND -n production -- curl http://localhost:3001/api/sante
```

**Qu'attendre:**
- DNS r√©sout correctement les noms de service
- La connectivit√© pod-to-pod fonctionne sans proxy

## 7. V√©rifier les Health Checks

**O√π ex√©cuter:** Machine locale avec kubectl
**Acc√®s requis:** Lecture sur pods
**R√¥le:** Developer

```bash
# Voir rapidement si tous les pods sont ready
kubectl get pods -n production

# Format d√©taill√© avec status
kubectl get pods -n production -o wide

# Voir l'√©tat des probes (Liveness/Readiness)
kubectl get pods -n production -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.containerStatuses[*].ready}{"\n"}{end}'

# Voir les d√©tails complets d'un pod
kubectl describe pod <POD_NAME> -n production
# Chercher les sections:
# - "Liveness probe": Status=Success ou Failed
# - "Readiness probe": Status=Success ou Failed
# - "Events": Montre les restarts ou erreurs r√©centes
```

**Qu'attendre:**
- Tous les pods affichent "Ready 1/1"
- Status "Running"
- Pas d'√©v√©nements d'erreur r√©cents

## 8. V√©rifier les Images et Versions

**O√π ex√©cuter:** Machine locale avec kubectl + gcloud CLI
**Acc√®s requis:** Lecture GHCR registry
**R√¥le:** Developer

```bash
# Voir les images utilis√©es dans le cluster
kubectl get pods -n production -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'

# V√©rifier que les images existent sur GHCR
gcloud container images describe ghcr.io/tsramb23/dgi-netwatch-backend:latest --show-tags
gcloud container images describe ghcr.io/tsramb23/dgi-netwatch-frontend:latest --show-tags

# Lister tous les tags disponibles
gcloud container images list-tags ghcr.io/tsramb23/dgi-netwatch-backend
gcloud container images list-tags ghcr.io/tsramb23/dgi-netwatch-frontend
```

**Qu'attendre:**
- Images existent sur GHCR
- Tags "latest" pointent vers les bonnes versions
- Pas d'erreurs d'authentification (si publiques)

## 9. Test End-to-End Complet

**O√π ex√©cuter:** Machine locale avec 3 terminaux
**Acc√®s requis:** Port-forward + kubectl
**R√¥le:** Developer

```bash
# ===== TERMINAL 1: Frontend =====
kubectl port-forward svc/dgi-netwatch-frontend-service 8080:80 -n production
# Attend: "Forwarding from 127.0.0.1:8080 -> 80"

# ===== TERMINAL 2: Backend =====
kubectl port-forward svc/dgi-netwatch-backend 3001:3001 -n production
# Attend: "Forwarding from 127.0.0.1:3001 -> 3001"

# ===== TERMINAL 3: Tests =====
# 1. V√©rifier que le frontend r√©pond
curl -s http://localhost:8080 | head -20

# 2. V√©rifier que le backend r√©pond
curl -s http://localhost:3001/api/sante

# 3. Ouvrir dans le navigateur
# URL: http://localhost:8080

# 4. Depuis le navigateur, v√©rifier que les requ√™tes API passent
# (Ouvrir les DevTools F12 > Console et Network)
```

**Qu'attendre:**
- Frontend charge le HTML/CSS/JS
- Backend r√©pond aux requ√™tes
- Pas d'erreurs CORS dans la console
- Les requ√™tes API affichent status 200

## 10. V√©rifier les Volumes et Stockage

**O√π ex√©cuter:** Machine locale avec kubectl + exec
**Acc√®s requis:** Exec sur pods
**R√¥le:** Developer

```bash
# Voir les volumes attach√©s au cluster
kubectl get pvc -n production
kubectl get pv

# Pour le backend qui utilise emptyDir, v√©rifier qu'il peut √©crire
BACKEND_POD=$(kubectl get pod -n production -l app=dgi-netwatch-backend -o jsonpath='{.items[0].metadata.name}')

# Exec dans le pod et v√©rifier le r√©pertoire
kubectl exec -it $BACKEND_POD -n production -- sh

# √Ä l'int√©rieur du pod:
ls -la /app/db/
du -sh /app/db/
touch /app/db/test.txt && rm /app/db/test.txt
exit
```

**Qu'attendre:**
- Le r√©pertoire /app/db existe
- Pas d'erreurs de permission
- √âcriture/lecture fonctionne

## 11. V√©rifier les Variables d'Environnement

**O√π ex√©cuter:** Machine locale avec kubectl + exec
**Acc√®s requis:** Exec sur pods
**R√¥le:** Developer

```bash
# Backend - Variables sp√©cifiques
BACKEND_POD=$(kubectl get pod -n production -l app=dgi-netwatch-backend -o jsonpath='{.items[0].metadata.name}')
kubectl exec $BACKEND_POD -n production -- env | grep -E "NODE_ENV|DB_PATH|PORT"

# Frontend - Variables sp√©cifiques
FRONTEND_POD=$(kubectl get pod -n production -l app=dgi-netwatch-frontend -o jsonpath='{.items[0].metadata.name}')
kubectl exec $FRONTEND_POD -n production -- env | grep -E "REACT_APP_API_URL"

# Toutes les variables
kubectl exec $BACKEND_POD -n production -- env | sort
```

**Qu'attendre:**
- NODE_ENV=production
- DB_PATH=/app/db/surveillance.db
- REACT_APP_API_URL=http://dgi-netwatch-backend:3001

## 12. Tester la R√©silience

**O√π ex√©cuter:** Machine locale avec kubectl
**Acc√®s requis:** Supprimer/cr√©er pods
**R√¥le:** Developer

```bash
# 1. V√©rifier l'√©tat initial
kubectl get pods -n production

# 2. Supprimer un pod backend (Kubernetes le recr√©era)
BACKEND_POD=$(kubectl get pod -n production -l app=dgi-netwatch-backend -o jsonpath='{.items[0].metadata.name}')
kubectl delete pod $BACKEND_POD -n production

# 3. Observer la recr√©ation (en direct)
kubectl get pods -n production --watch

# 4. V√©rifier qu'un nouveau pod est cr√©√©
kubectl get pods -n production

# 5. Voir les √©v√©nements
kubectl describe deployment dgi-netwatch-backend -n production
# Chercher "Events" pour voir Pod cr√©ations/suppressions
```

**Qu'attendre:**
- Pod supprim√© imm√©diatement recr√©√©
- Nouveau pod en status "Running" dans quelques secondes
- D√©ploiement maintient toujours 1 replique

## 13. V√©rifier les Ressources

**O√π ex√©cuter:** Machine locale avec kubectl
**Acc√®s requis:** Lecture metrics
**R√¥le:** Developer

```bash
# Utilisation actuelle des n≈ìuds
kubectl top nodes

# Utilisation actuelle des pods
kubectl top pods -n production

# Requests et limits d√©finis dans les configs
kubectl get pods -n production -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{.spec.containers[*].resources}{"\n\n"}{end}'

# Plus lisible:
kubectl describe pod $(kubectl get pod -n production -l app=dgi-netwatch-backend -o jsonpath='{.items[0].metadata.name}') -n production | grep -A 5 "Requests\|Limits"
```

**Qu'attendre:**
- Backend: CPU 100m, RAM 128Mi (requests)
- Frontend: CPU 100m, RAM 128Mi (requests)
- Utilisation r√©elle < requests configur√©es

## 14. Nettoyer et Tester le Red√©ploiement

**O√π ex√©cuter:** Machine locale (terminal + kubectl)
**Acc√®s requis:** Terraform destroy + kubectl delete
**R√¥le:** Admin/Developer

```bash
# Optionnel: Supprimer tout et red√©ployer (test destructif)

# 1. V√©rifier l'√©tat actuel
kubectl get all -n production

# 2. Supprimer via Terraform
cd terraform
terraform plan -destroy -out=tfplan-destroy

# 3. Examiner le plan
cat tfplan-destroy

# 4. Appliquer la destruction
terraform apply tfplan-destroy

# 5. V√©rifier que tout est supprim√©
kubectl get namespace production
kubectl get all -n production

# 6. Red√©ployer
terraform apply -auto-approve

# 7. V√©rifier la recr√©ation
kubectl get pods -n production --watch
```

**Qu'attendre:**
- Tous les pods supprim√©s avec `terraform destroy`
- Tous les pods recr√©√©s avec `terraform apply`
- √âtat identique avant/apr√®s le cycle

## Checklist de Test Rapide

- [ ] Pods sont tous en status "Running"
- [ ] Health checks (Liveness/Readiness) passent
- [ ] Frontend accessible via port-forward
- [ ] Backend r√©pond √† /api/sante
- [ ] Frontend peut communiquer avec Backend
- [ ] Logs ne montrent pas d'erreurs
- [ ] Images Docker sont les bonnes versions
- [ ] Variables d'environnement sont correctes
- [ ] Volumes et stockage fonctionnent
- [ ] Services sont correctement connect√©s
- [ ] Tests end-to-end r√©ussissent

## Troubleshooting Rapide

| Probl√®me | Commande |
|----------|----------|
| Pod crashe | `kubectl logs <POD> -n production` |
| Pod ne d√©marre pas | `kubectl describe pod <POD> -n production` |
| Backend inaccessible | `kubectl get svc -n production` |
| Frontend blanc | `kubectl logs <FRONTEND_POD> -n production` |
| Pas de connectivit√© | `kubectl exec <POD> -n production -- nslookup dgi-netwatch-backend` |
